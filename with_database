import os
import gc
import cv2
import numpy as np
import urllib.request
import pandas as pd
from datetime import datetime
from face_recognition import face_encodings, face_locations, face_distance
from google.cloud import firestore
from gtts import gTTS
import threading
import subprocess
import base64

# Ensure TensorFlow uses CPU only
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

# ESP32-CAM Stream URL
url = 'http://192.168.88.11/cam-hi.jpg'  # Adjust to your ESP32-CAM URL

# Attendance tracking
attendance_folder = os.path.join(os.getcwd(), 'attendance')
attendance_file = os.path.join(attendance_folder, "Attendance.csv")
os.makedirs(attendance_folder, exist_ok=True)
if not os.path.exists(attendance_file):
    pd.DataFrame(columns=["Name", "Time"]).to_csv(attendance_file, index=False)

# Firestore Initialization
COLLECTION_NAME = "photos"  # Replace with your Firestore collection name

# Function to verify Firestore connection
def verify_firestore_connection():
    try:
        print("Initializing Firestore client...")
        db = firestore.Client()
        print("Firestore client connected successfully!")

        # Test fetching documents
        print(f"Fetching documents from collection '{COLLECTION_NAME}'...")
        docs = db.collection(COLLECTION_NAME).stream()

        document_found = False
        for doc in docs:
            document_found = True
            print(f"Document ID: {doc.id}")
            print(f"Document Data: {doc.to_dict()}")
            print("-" * 50)

        if not document_found:
            print(f"No documents found in collection '{COLLECTION_NAME}'.")
        else:
            print("All documents fetched successfully!")
        return db
    except Exception as e:
        print(f"Error connecting to Firestore: {e}")
        raise

# Mark attendance
def markAttendance(name):
    try:
        df = pd.read_csv(attendance_file)
        if name not in df["Name"].values:
            now = datetime.now()
            dtString = now.strftime('%H:%M:%S')
            new_entry = pd.DataFrame({"Name": [name], "Time": [dtString]})
            df = pd.concat([df, new_entry], ignore_index=True)
            df.to_csv(attendance_file, index=False)
    except Exception as e:
        print(f"Error saving attendance: {e}")

# Load face encodings from Firestore
def load_faces_from_firestore(db):
    known_encodings = []
    class_names = []
    try:
        docs = db.collection(COLLECTION_NAME).stream()
        for doc in docs:
            data = doc.to_dict()
            name = data.get("description", "Unknown")
            image_base64 = data.get("image", "")

            # Decode base64 image
            if image_base64:
                img_data = np.frombuffer(bytearray(base64.b64decode(image_base64)), dtype=np.uint8)
                img = cv2.imdecode(img_data, cv2.IMREAD_COLOR)
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                encodings = face_encodings(img_rgb)
                if encodings:
                    known_encodings.append(encodings[0])
                    class_names.append(name)
        print("Face encodings loaded successfully from Firestore.")
    except Exception as e:
        print(f"Error loading faces from Firestore: {e}")
    return known_encodings, class_names

# Text-to-speech
def speak(text):
    try:
        tts = gTTS(text=text, lang='en')
        tts.save("temp_audio.mp3")
        subprocess.call(["mpg321", "temp_audio.mp3"])  # Replace with the appropriate command for your system
    except Exception as e:
        print(f"Error with gTTS speech: {e}")

# Process frames
frame_count = 0
def process_frame(img, known_encodings, class_names):
    global frame_count
    try:
        # Resize image
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        faces = face_locations(img_rgb, model="hog")
        encodesCurFrame = face_encodings(img_rgb, faces)

        for encodeFace, faceLoc in zip(encodesCurFrame, faces):
            faceDist = face_distance(known_encodings, encodeFace)
            matchIndex = np.argmin(faceDist) if faceDist.size > 0 else -1
            name = class_names[matchIndex].upper() if matchIndex != -1 and faceDist[matchIndex] < 0.6 else "UNKNOWN"
            if name != "UNKNOWN":
                markAttendance(name)
                threading.Thread(target=speak, args=(f"{name} Detected",)).start()
            print(name)

            # Draw rectangles around faces
            y1, x2, y2, x1 = faceLoc
            color = (0, 255, 0) if name != "UNKNOWN" else (0, 0, 255)
            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
            cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)

        # Display frame
        cv2.imshow("ESP32-CAM Stream", img)
        frame_count += 1
        gc.collect()
    except Exception as e:
        print(f"Error processing frame: {e}")

# Main Function
if __name__ == "__main__":
    try:
        # Verify Firestore connection
        db = verify_firestore_connection()

        # Load known faces from Firestore
        known_encodings, class_names = load_faces_from_firestore(db)

        # Main loop for ESP32-CAM stream
        while True:
            try:
                img_resp = urllib.request.urlopen(url)
                imgnp = np.array(bytearray(img_resp.read()), dtype=np.uint8)
                img = cv2.imdecode(imgnp, -1)

                # Resize and rotate the image if needed
                img = cv2.resize(img, (640, 480))
                img = cv2.transpose(img)
                img = cv2.flip(img, flipCode=0)

                # Process frame
                process_frame(img, known_encodings, class_names)

                # Exit on 'q' key press
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
            except Exception as e:
                print(f"Error processing webcam stream: {e}")
                break

        cv2.destroyAllWindows()
    except Exception as e:
        print(f"Fatal error: {e}")